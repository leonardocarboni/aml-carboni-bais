{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning - programming assignment 4\n",
    "\n",
    "*Due: Friday January 27*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please fill in:**\n",
    "* Bais Giacomo (5355583)\n",
    "* Carboni Leonardo (0279048)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further instructions:\n",
    "* Make sure your code is properly commented.\n",
    "* Submit your code in Blackboard using one of your accounts; we will put the grade in Blackboard for the other team member as well.\n",
    "* **Make sure to name the submitted file according to your and your collaborators last name.** (`submitter_collaborator.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the PC algorithm\n",
    "In this assignment, you will complete an implementation of the PC algorithm. After that, you will use it to discover causal relations in a data set. Each of these two parts is worth 5 points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PC algorithm will need to keep track of a PDAG. We will represent this PDAG by a numpy array `G` of booleans.\n",
    "\n",
    "The matrix `G` represents a graph as follows:\n",
    "* For all `x`, `G[x,x] == False`\n",
    "* `G[x,y] == False` and `G[y,x] == False` means: no edge between x and y\n",
    "* `G[x,y] == True` and `G[y,x] == True` means: an undirected edge x&mdash;y\n",
    "* `G[x,y] == True` and `G[y,x] == False`means: a directed edge x$\\to$y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import graphviz # Install with: conda install python-graphviz\n",
    "\n",
    "from AML_assignment4_util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphviz can draw graphs to different file formats, or show them directly in the notebook. The function `graph_to_graphviz(G, node_names)` converts a numpy array of the form described above to a graph in graphviz format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.50.0 (0)\n -->\n<!-- Pages: 1 -->\n<svg width=\"440pt\" height=\"44pt\"\n viewBox=\"0.00 0.00 440.00 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 436,-40 436,4 -4,4\"/>\n<!-- X -->\n<g id=\"node1\" class=\"node\">\n<title>X</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n</g>\n<!-- Y -->\n<g id=\"node2\" class=\"node\">\n<title>Y</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"153\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"153\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n</g>\n<!-- X&#45;&gt;Y -->\n<g id=\"edge1\" class=\"edge\">\n<title>X&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54.03,-18C71.93,-18 95.65,-18 115.38,-18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.58,-21.5 125.58,-18 115.58,-14.5 115.58,-21.5\"/>\n</g>\n<!-- Z -->\n<g id=\"node3\" class=\"node\">\n<title>Z</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"279\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"279\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Z</text>\n</g>\n<!-- Z&#45;&gt;Y -->\n<g id=\"edge2\" class=\"edge\">\n<title>Z&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M251.97,-18C234.07,-18 210.35,-18 190.62,-18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"190.42,-14.5 180.42,-18 190.42,-21.5 190.42,-14.5\"/>\n</g>\n<!-- W -->\n<g id=\"node4\" class=\"node\">\n<title>W</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"405\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"405\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">W</text>\n</g>\n<!-- Z&#45;&gt;W -->\n<g id=\"edge3\" class=\"edge\">\n<title>Z&#45;&gt;W</title>\n<path fill=\"none\" stroke=\"black\" d=\"M306.03,-18C327.14,-18 356.37,-18 377.58,-18\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fc4f03be650>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstration of graph_to_graphviz:\n",
    "node_names = ['X', 'Y', 'Z', 'W']\n",
    "G1 = np.zeros((4,4), dtype=bool)\n",
    "G1[0,1] = G1[2,1] = True # two directed edges\n",
    "G1[2,3] = G1[3,2] = True # an undirected edge\n",
    "d = graph_to_graphviz(G1, node_names)\n",
    "d # must be final line of code block to be displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a Python class for performing the PC algorithm (when an object of this class is created and its `run` function is called). Add the missing code for phase 2, and implement phases 3 and 4. In the next section, you'll find some test cases to see if your code runs without errors and does what you expect it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PC_algorithm:\n",
    "    def __init__(self, independence_tester, verbose=1):\n",
    "        # verbose can be 0 (silent), 1 (report independences), or 2 (also report dependences)\n",
    "        self.independence_tester = independence_tester\n",
    "        self.n = independence_tester.n_observed\n",
    "        self.node_names = independence_tester.node_names\n",
    "        self.verbose = verbose\n",
    "        self.G = np.logical_not(np.eye(self.n, dtype=bool))\n",
    "        self.sepset = dict()\n",
    "    \n",
    "    def skeleton_search(self):\n",
    "        # PHASE II: Skeleton search\n",
    "        # Note: Adj(X) in the slides means: all nodes adjacent to X in the current graph G\n",
    "        for k in range(self.n-1):\n",
    "            for x in range(self.n):\n",
    "                for y in range(self.n):\n",
    "                    if not self.G[x,y]: #if they don't have an edge\n",
    "                        continue\n",
    "                    # Try all subsets S of Adj(x) \\ {y} with |S|=k,\n",
    "                    # until an independence is found.\n",
    "                    # Hint: use itertools.combinations\n",
    "\n",
    "                    # Your code here (1 point)\n",
    "                    \n",
    "                    for S in itertools.combinations(self.G, x): #TODO: check\n",
    "                        indep = self.independence_tester.test_independence(x, y, S)\n",
    "                        if indep:\n",
    "                            if self.verbose >= 1:\n",
    "                                print(\"independence found: {0} and {1} given {{{2}}}\"\n",
    "                                      .format(self.node_names[x], self.node_names[y],\n",
    "                                              \", \".join([self.node_names[v] for v in S])))\n",
    "                            # Remove this edge.\n",
    "                            self.G[x,y] = self.G[y,x] = False\n",
    "                            # We use frozensets as keys in the dictionary self.sepset,\n",
    "                            # because ordinary sets can't be used as keys to dictionaries.\n",
    "                            self.sepset[frozenset([x,y])] = S\n",
    "                            break\n",
    "                        else:\n",
    "                            if self.verbose >= 2:\n",
    "                                print(\"dependence found: {0} and {1} given {{{2}}}\"\n",
    "                                      .format(self.node_names[x], self.node_names[y],\n",
    "                                              \", \".join([self.node_names[v] for v in S])))\n",
    "            # Do we need to continue with larger k?\n",
    "            max_S_size = np.sum(self.G, axis=0) - 1\n",
    "            if np.all(max_S_size < k + 1):\n",
    "                break\n",
    "        return\n",
    "\n",
    "    def orient_v_structures(self):\n",
    "        # PHASE III: Orient v-structures\n",
    "        # Something to watch out for:\n",
    "        # If the data are not faithful to any graph, the algorithm may end up trying\n",
    "        # to orient a single edge in two different ways. You can choose either\n",
    "        # orientation if this happens. But make sure not to accidentally delete such an edge!\n",
    "\n",
    "        # Your code here (2 points)\n",
    "        # implement v-structures orientation\n",
    "        \n",
    "        #TODO: check\n",
    "        for x in range(self.n):\n",
    "                for y in range(self.n):\n",
    "                    if not self.G[x,y]: #unonriented pages\n",
    "                        for z in np.unique(np.concatenate(itertools.combinations(self.G, x), itertools.combinations(self.G, y))):\n",
    "                            if z not in self.sepset[x, y]:\n",
    "                                self.G[x, z] = True\n",
    "                                self.G[y, z] = True\n",
    "                        \n",
    "        return\n",
    "    \n",
    "    def orientation_rules(self):\n",
    "        # PHASE IV: Orientation rules\n",
    "\n",
    "        # Your code here (2 points)\n",
    "        \n",
    "        def rule1(g):\n",
    "            pairs = [(i, j) for i in range(self.n) for j in range(self.n) if g[i][j] == 1 and g[j][i] == 0]\n",
    "            for i, j in pairs:\n",
    "                all_k = [k for k in range(self.n) if (g[j][k] == 1 and g[k][j] == 1) and (g[i][k] == 0 and g[k][i] == 0)]\n",
    "\n",
    "                if len(all_k) > 0:\n",
    "                    g[j][all_k] = 1\n",
    "                    g[all_k][j] = 0\n",
    "\n",
    "            return g\n",
    "\n",
    "        def rule2(g):\n",
    "            pairs = [(i, j) for i in range(self.n) for j in range(self.n) if g[i][j] == 1 and g[j][i] == 1]\n",
    "            for i, j in pairs:\n",
    "                all_k = [k for k in range(self.n) if (g[i][k] == 1 and g[k][i] == 0) and (g[k][j] == 1 and g[j][k] == 0)]\n",
    "                if len(all_k) > 0:\n",
    "                    g[i][j] = 1\n",
    "                    g[j][1] = 0\n",
    "            return g\n",
    "\n",
    "        def rule3(g):\n",
    "            pairs = [(i, j) for i in range(self.n) for j in range(self.n) if g[i][j] == 1 and g[j][i] == 1]\n",
    "            for i, j in pairs:\n",
    "                all_k = [k for k in range(self.n) if (g[i][k] == 1 and g[k][i] == 1) and (g[k][j] == 1 and g[j][k] == 0)]\n",
    "                if len(all_k) >= 2:\n",
    "                    for k1, k2 in itertools.combinations(all_k, 2):\n",
    "                        if g[k1][k2] == 0 and g[k2][k1] == 0:\n",
    "                            g[i][j] = 1\n",
    "                            g[j][i] = 0\n",
    "                            break\n",
    "            return g\n",
    "    \n",
    "        \n",
    "        pairs = [(i, j) for i in range(self.n) for j in range(self.n) if self.G[i][j] == 1]\n",
    "\n",
    "        for x, y in sorted(pairs, key=lambda x:(x[1], x[0])):\n",
    "            all_z = [z for z in range(self.n) if self.G[y][z] == 1 and z != x]\n",
    "\n",
    "            for z in all_z:\n",
    "                if self.G[x,z] == 0 and y not in self.sepset[x,z]:\n",
    "                    self.G[x,y] = self.G[z,y] = 1\n",
    "                    self.G[y,x] = self.G[y,z] = 0\n",
    "\n",
    "        # Orientation rule 1 - rule 3\n",
    "        old_G = np.zeros((self.n, self.n))\n",
    "\n",
    "        while not np.array_equal(old_G, self.G):\n",
    "            old_G = self.G.copy()\n",
    "\n",
    "            G = rule1(self.G)\n",
    "            G = rule2(self.G)\n",
    "            G = rule3(self.G)\n",
    "\n",
    "        return np.array(self.G)\n",
    "\n",
    "    def run(self):\n",
    "        # The initialization step has already been performed by the __init__ method.\n",
    "        # Perform the other phases one by one. Each of the following functions\n",
    "        # modifies self.G, which represents the graph.\n",
    "        self.skeleton_search()\n",
    "        self.orient_v_structures()\n",
    "        self.orientation_rules()\n",
    "\n",
    "        return self.G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the PC implementation\n",
    "\n",
    "To verify that the algorithm is working correctly, we will feed it output from an *oracle* instead of conditional independence test results from a data set. The oracle knows what the true graph is, and mimics the conditional independence test results that we would get for data that is Markov and faithful to that graph. In this situation, the PC algorithm will recover the Markov equivalence class of the true graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndependenceOracle:\n",
    "    def __init__(self, true_G, node_names, n_observed=None):\n",
    "        self.G = true_G\n",
    "        self.n = true_G.shape[0]\n",
    "        self.n_observed = n_observed if n_observed is not None else self.n\n",
    "        self.node_names = node_names\n",
    "    def test_independence(self, x, y, S):\n",
    "        S_mask = np.zeros(self.n, dtype=bool)\n",
    "        np.put(S_mask, S, True)\n",
    "        return is_d_separated(self.G, x, y, S_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the output of PC to the oracle's true graph for the graph `G1` we saw before, and for several other graphs. (You can add more tests to help chase down any bugs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m oracle \u001b[39m=\u001b[39m IndependenceOracle(G1, node_names)\n\u001b[1;32m      2\u001b[0m A \u001b[39m=\u001b[39m PC_algorithm(oracle, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m G \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mrun()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G1' is not defined"
     ]
    }
   ],
   "source": [
    "oracle = IndependenceOracle(G1, node_names)\n",
    "A = PC_algorithm(oracle, verbose=2)\n",
    "G = A.run()\n",
    "print(\"PASS\" if np.all(G == G1) else \"FAIL\")\n",
    "graph_to_graphviz(G, oracle.node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = np.zeros((4,4), dtype=bool)\n",
    "G2[0,2] = G2[1,2] = G2[2,3] = True\n",
    "graph_to_graphviz(G2, node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = IndependenceOracle(G2, node_names)\n",
    "A = PC_algorithm(oracle)\n",
    "G = A.run()\n",
    "print(\"PASS\" if np.all(G == G2) else \"FAIL\")\n",
    "graph_to_graphviz(G, oracle.node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G3 = np.zeros((4,4), dtype=bool)\n",
    "G3[0,2] = G3[1,2] = G3[1,3] = G3[2,3] = True\n",
    "graph_to_graphviz(G3, node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = IndependenceOracle(G3, node_names)\n",
    "A = PC_algorithm(oracle)\n",
    "G = A.run()\n",
    "print(\"PASS\" if np.all(G == G3) else \"FAIL\")\n",
    "graph_to_graphviz(G, oracle.node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G4 = np.logical_not(np.eye(4, dtype=bool))\n",
    "G4[0,1] = G4[1,0] = False\n",
    "G4[3,0] = G4[3,1] = G4[3,2] = False\n",
    "graph_to_graphviz(G4, node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = IndependenceOracle(G4, node_names)\n",
    "A = PC_algorithm(oracle)\n",
    "G = A.run()\n",
    "print(\"PASS\" if np.all(G == G4) else \"FAIL\")\n",
    "graph_to_graphviz(G, oracle.node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a case for which no DAG exists that is Markov and faithful to the distribution.\n",
    "# L is a latent variable that the PC algorithm won't know about. PC's output should be either\n",
    "# X --> Y --> Z <-- W or\n",
    "# X --> Y <-- Z <-- W.\n",
    "# If there is no edge between Y and Z in your output, this most likely indicates a bug in\n",
    "# your implementation of phase III.\n",
    "G5 = np.zeros((5,5), dtype=bool)\n",
    "G5[0,1] = G5[4,1] = True\n",
    "G5[3,2] = G5[4,2] = True\n",
    "graph_to_graphviz(G5, ['X', 'Y', 'Z', 'W', 'L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = IndependenceOracle(G5, node_names, n_observed = 4)\n",
    "A = PC_algorithm(oracle)\n",
    "G = A.run()\n",
    "print(\"PASS\" if G[0,1] and G[3,2] and (G[1,2] or G[2,1]) and np.sum(np.logical_or(G, G.T)) == 6 else \"FAIL\")\n",
    "graph_to_graphviz(G, oracle.node_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running PC on data\n",
    "In this second part of the assignment, you will apply the PC algorithm to the biological dataset of Sachs et al. (2005). In this dataset, the columns represent 11 different proteins, which were measured in thousands of human immune system cells. Each row is a single cell. The cells were prepared in different ways, by adding different chemicals some time before the measurements were made. A twelfth column, labeled `experiment`, indicates in which way that cell was prepared. We can think of `experiment=1` as denoting the observational data, and other values of `experiment` (2 through 14) as various interventional datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_data = pd.read_csv(\"sachs2005_combined.csv\", sep='\\t')\n",
    "# Transform all columns except 'experiment' by taking the logarithm of 10 + the original value\n",
    "all_data.loc[:, all_data.columns != 'experiment'] = np.log(10 + all_data.loc[:, all_data.columns != 'experiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply the PC algorithm to just the observational data.\n",
    "\n",
    "Make a new dataframe containing only the data where experiment equals 1. Remove the `experiment` column from this dataframe. Check the shape of your dataframe: it should be `(853, 11)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (0.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next part, you will need to install the package [tigramite](https://github.com/jakobrunge/tigramite). Here are three different ways in which you might be able to install it, in the order in which we recommend you to try them:\n",
    "\n",
    "1. `conda install -c egilliesix tigramite`\n",
    "\n",
    "2. `conda install git pip`  \n",
    "`pip install git+git://github.com/jakobrunge/tigramite.git`\n",
    "\n",
    "3. If not in a conda environment, follow the README on github.\n",
    "\n",
    "To run the PC algorithm on data, we need to perform (conditional) independence tests. Tigramite implements several such tests. The simplest of these tests is `ParCorr()`. It assumes the data come from a linear structural causal model, which they actually don't. We will use it anyway, because the alternatives (such as `CMIknn()` (Runge, 2018)) are more effort to install and orders of magnitude slower, while `ParCorr()` usually already gives decent results.\n",
    "\n",
    "As a statistical test, a conditional independence test works by computing a p-value. If a conditional independence exists, this p-value will be approximately uniformly distributed on the interval between 0 and 1. If the variables being tested are conditionally dependent, the p-value will be close to 0. PC wants to know a binary answer, so we will pick some threshold alpha and declare an independence if the p-value is larger than alpha.\n",
    "\n",
    "In statistical testing, alpha is often taken to be 0.05 or smaller. For PC, it may be more appropriate to pick a larger alpha instead. This is because as soon as PC finds a (conditional) independence between two variables, it will delete the edge between them and do no more tests between those two variables. If this happens while it shouldn't have, PC can't put the edge back. But in the reverse situation, if PC leaves an edge in place while it should have deleted it, there is still a possibility that the edge will be deleted later, when another test between those two variables reports a more convincing independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tigramite.independence_tests import ParCorr#, CMIknn\n",
    "import tigramite.data_processing as pp\n",
    "# Importing these may give some warnings (e.g. 'Could not import r-package RCIT'),\n",
    "# but most of these warnings can be ignored because we are not using the mentioned packages.\n",
    "\n",
    "class IndependenceTester:\n",
    "    def __init__(self, data, cond_ind_test, alpha, verbose=2, n_observed=None):\n",
    "        # data: a pandas dataframe\n",
    "        # cond_ind_test: an independence test from tigramite, e.g. ParCorr()\n",
    "        # alpha: the significance level to which the p-values are compared\n",
    "        \n",
    "        # tigramite uses its own kind of dataframe, so convert the data to that format\n",
    "        df_tigramite = pp.DataFrame(data.to_numpy(), var_names=data.columns)\n",
    "        self.cond_ind_test = cond_ind_test\n",
    "        self.cond_ind_test.set_dataframe(df_tigramite)\n",
    "        self.n = data.shape[1]\n",
    "        self.n_observed = n_observed if n_observed is not None else self.n\n",
    "        self.verbose = verbose\n",
    "        self.node_names = data.columns\n",
    "        self.alpha = alpha\n",
    "    def test_independence(self, x, y, S):\n",
    "        val, pval = self.cond_ind_test.run_test(X=[(x, 0)],\n",
    "                                                Y=[(y, 0)],\n",
    "                                                Z=[(z, 0) for z in S])\n",
    "        test_result = pval > self.alpha\n",
    "        if self.verbose >= 2 or (self.verbose >= 1 and test_result):\n",
    "            print(\"test: {0} and {1} given {2} -> pval={3}\".format(self.node_names[x], self.node_names[y],\n",
    "                                                                   \", \".join([self.node_names[v] for v in S]),\n",
    "                                                                   pval))\n",
    "        return test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an IndependenceTester object (which works similarly to the IndependenceOracle we used earlier), run the PC algorithm on the observational data. Display the graph that comes out. You may experiment with different values of alpha; the graph you get should either be connected (i.e. consist of one [connected component](https://en.wikipedia.org/wiki/Component_%28graph_theory%29)), or have just two connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at what else is in the dataset: the interventional data corresponding to different experiments. The PC algorithm did not look at this part of the dataset, but these additional experiments can obviously provide valuable information about the causal graph. In the following questions, we will investigate two examples of this. We will use the output of the PC algorithm to give us a rough idea of what the causal graph might look like.\n",
    "\n",
    "The interventions in these experiment are not perfect interventions: they change the structural equation of a variable, but not by setting it to a constant. The new structural equation in the intervened model may still include all variables that were there in the original model. So in the graph of the intervened model, all arrows will still be there.\n",
    "\n",
    "Further, some of the interventions change not one, but multiple structural equations.\n",
    "\n",
    "For some of the interventions in the data, here is what they do according to many (but not all) experts:\n",
    "* experiment 5 adds the substance psitectorigenin, which modifies the amount of PIP2;\n",
    "* experiment 6 adds the substance U0126, which increases the *activity* of pmek. This means that the amount of pmek is not changed by the intervention, but for all *children* of pmek in the causal model, the structural equation changes to reflect that pmek now has a stronger effect on them. pmek is believed to have only one child in the true causal model, namely perk.\n",
    "\n",
    "(Source: Mooij et al., 2019, specifically Tables 2 & 3 and Figure 35(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two new dataframes, one containing all data from experiments 1 and 5, and one with the data from experiments 1 and 6. These dataframes should still have an 'experiment' column, so that you can tell for each row whether it came from the observational or the interventional dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (0.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question (1.5 points)**: In the dataframe for experiments 1 and 5, look at PIP2 and a variable adjacent to it in the output of PC (if there is more than one, pick one). Using about 200 words, answer the following questions: Based on looking at one or more plots (like scatterplots or histograms), which do you find more likely: that psitectorigenin directly modifies PIP2, or the neighbouring variable, or both? And what does the data for the two experiments seem to say about the direction of the arrow between PIP2 and its neighbour?\n",
    "\n",
    "Insert one or more markdown and code boxes below here to give your answer and the plots you base your answer on. (Please put your answer in markdown boxes, not as comments in your code!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question (1.5 points)**: In the dataframe for experiments 1 and 6, look at pmek, perk, and any other variables adjacent to pmek in the output of PC. Assume it is true that adding U0126 produces an intervention on the *activity* of pmek. What would you expect to see in the data if the graph found by PC was correct? Would you propose any changes to that graph based on the data?\n",
    "\n",
    "Again put your answer (about 200 words) with accompanying plots in new boxes below here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You are almost done! Before handing in, make sure that the code you hand in works, and that all plots are shown. **Submit just one file per team.** Name the submitted file according to your and your collaborator's last name (`submitter_collaborator.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* J. M. Mooij, S. Magliacane, and T. Claassen, \"Joint Causal Inference from Multiple Contexts,\" [arXiv:1611.10351v4](https://arxiv.org/abs/1611.10351), 2019.\n",
    "* J. Runge, \"Conditional Independence Testing Based on a Nearest-Neighbor Estimator of Conditional Mutual Information\" In Proceedings of the 21st International Conference on Artificial Intelligence and Statistics, http://proceedings.mlr.press/v84/runge18a.html, 2018.\n",
    "* K. Sachs, O. Perez, D. Pe’er, D. A. Lauffenburger, and G. P. Nolan, \"Causal protein-signaling networks derived from multiparameter single-cell data,\" Science, vol. 308, no. 5721, pp. 523–529, 2005."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e73927171d62f529ca1aa599ee0b84007adc4c716ac382f2cb4878b3f065b61e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
